{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5791003e",
   "metadata": {},
   "source": [
    "# main ideas\n",
    "\n",
    "## The first stock Pattern I want to find is:\n",
    "\n",
    "* we need the time to be hours, the first 12-24 hours\n",
    "\n",
    "0. the 5-10% doesn't mean the stock price end on that day with a 5% raise, it means during the 1-2 days, it reach that point. so stage1 and stage2 also doesn't have to be in day 1 stage1, day 2-5 stage2, it can be day1 stage1, day1 also starts stage2, the day1 2 3 4 is more about the length.\n",
    "1. Stage1, Big rasie: the first 6-12 hours(2 days), the stock raise about 5-10%, \n",
    "\n",
    "2. Stage2: Consolidating: after that rise, the 6-30 hours(2-6 days) days the stock consolidating around that price(no more than 5% than stage1 lowest or highest price )   \n",
    "3. Stage3: Decreasing Volume: it shows Doji/or other indecisive trading siganl with decreasing volume right after at least 12 hours min 30 hours max 2 days(at most 5days) of consolidating\n",
    "\n",
    "will it make difference though? \n",
    "\n",
    "## Buy Point: and we buy at the next day of stage3 siganl\n",
    "## Sell Point: we sell at the next day of buying \n",
    "\n",
    "I want to code to be:\n",
    "0.modular so that I can adjust and add other stage and easy to maintain\n",
    "1.accepet parameters(like stage1 it may be 7-12% instead of 5-10%, the last period of stage 1 maybe 1-4days instead of 1-2days)\n",
    "2.I can test it with simulation, like I run it during a period of time form 2025/1/1 to 2025/3/1 and buy and the mid price at the buy point, and sell at the mid price at the sell point, how many profits can I have\n",
    "3.I can use the simulation resualts to adjust the parameters to get more profit automatically \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Can we use code to detect the patterns?\n",
    "* we observe and research the profitable patterns, we observe instead of guessing from no reason,\n",
    "    * for the consolidating time\n",
    "        * at least up down and up \n",
    "        * or just stay there \n",
    "\n",
    "\n",
    "* use code to optimize the profit\n",
    "* first we can use code to detect the hot rasing areas like IT / medical / \n",
    "* classify the rasing stocks based on different \n",
    "    * market times \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d3699e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myfinance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "code = 'AAPL'\n",
    "start_date = '2025-05-07'\n",
    "end_date ='2025-05-09'\n",
    "df = yf.download(\"AAPL\", start=start_date, end=end_date, interval=\"1d\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86165966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern.py\n",
    "\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# We define a PatternParams class to hold all tunable parameters for the pattern definition. \n",
    "# This makes it easy to adjust thresholds or extend with new parameters. \n",
    "\n",
    "# is_stage3_signal(idx, daily_df): Checks if the day at idx in the daily DataFrame is an indecisive candlestick (doji) with volume lower \n",
    "# than previous days (Stage 3 criteria).\n",
    "\n",
    "# is_consolidation(start_idx, end_idx, daily_df): Checks if the price between start_idx and end_idx (inclusive) stayed within a tight range \n",
    "# (Stage 2 criteria).\n",
    "\n",
    "# is_big_rise(start_idx, end_idx, daily_df): Checks if there was a rise of the required percentage between start_idx and end_idx (Stage 1 criteria).\n",
    "\n",
    "# find_signals(hourly_df): Converts hourly data to daily, then iterates through each potential Stage 3 day and verifies if preceding Stage 2 and Stage 1 \n",
    "# conditions are met. Returns a list of detected pattern signals (with buy/sell info).\n",
    "\n",
    "# pattern_hourly.py\n",
    "\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PatternParams:\n",
    "    # Stage 1: Big Rise\n",
    "    rise_min: float = 0.02           # 5%\n",
    "    rise_max: float = 0.10           # 10%\n",
    "    stage1_min_hours: int = 6\n",
    "    stage1_max_hours: int = 12\n",
    "\n",
    "    # Stage 2: Consolidation\n",
    "    cons_min_hours: int = 6\n",
    "    cons_max_hours: int = 30\n",
    "    cons_max_range: float = 0.09     # 5% range\n",
    "\n",
    "    # Stage 3: Doji + Volume Drop\n",
    "    doji_body_frac: float = 0.6\n",
    "    vol_compare_hours: int = 2       # must be lower than N previous bars\n",
    "\n",
    "class PatternDetector:\n",
    "    def __init__(self, params: PatternParams = None):\n",
    "        self.params = params or PatternParams()\n",
    "\n",
    "    def is_doji(self, row) -> bool:\n",
    "        high, low = row['High'], row['Low']\n",
    "        open_, close = row['Open'], row['Close']\n",
    "        if high == low:\n",
    "            return False\n",
    "        body = abs(open_ - close)\n",
    "        range_ = high - low\n",
    "        return body <= self.params.doji_body_frac * range_\n",
    "\n",
    "    def is_volume_dropped(self, idx: int, df: pd.DataFrame) -> bool:\n",
    "        if idx < self.params.vol_compare_hours:\n",
    "            return False\n",
    "        curr_vol = df.iloc[idx]['Volume']\n",
    "        prev_vol = df.iloc[idx - self.params.vol_compare_hours:idx]['Volume']\n",
    "        return (prev_vol > curr_vol).all()\n",
    "\n",
    "    def is_consolidating(self, df: pd.DataFrame) -> bool:\n",
    "        high = df['High'].max()\n",
    "        low = df['Low'].min()\n",
    "        return (high - low) / low <= self.params.cons_max_range\n",
    "\n",
    "    def find_signals(self, df: pd.DataFrame):\n",
    "        signals = []\n",
    "        n = len(df)\n",
    "        for i in range(n - self.params.stage1_min_hours - self.params.cons_min_hours - 2):\n",
    "            # Stage 1: Look for rise\n",
    "            for h1 in range(self.params.stage1_min_hours, self.params.stage1_max_hours + 1):\n",
    "                stage1 = df.iloc[i:i + h1]\n",
    "                if stage1.empty:\n",
    "                    continue\n",
    "                low = stage1['Low'].min()\n",
    "                high = stage1['High'].max()\n",
    "\n",
    "                try:\n",
    "                    low = float(low.iloc[0]) if hasattr(low, 'iloc') else float(low)\n",
    "                    high = float(high.iloc[0]) if hasattr(high, 'iloc') else float(high)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if low == 0:\n",
    "                    continue\n",
    "\n",
    "                rise = (high - low) / low\n",
    "\n",
    "                try:\n",
    "                    rise = float(rise)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if not (self.params.rise_min <= rise <= self.params.rise_max):\n",
    "                    continue\n",
    "\n",
    "                # Stage 2: Look for consolidation right after Stage 1\n",
    "                stage2_start = i + h1\n",
    "                for h2 in range(self.params.cons_min_hours, self.params.cons_max_hours + 1):\n",
    "                    if stage2_start + h2 + 1 >= n:\n",
    "                        break\n",
    "                    stage2 = df.iloc[stage2_start:stage2_start + h2]\n",
    "                    if stage2.empty:\n",
    "                        continue\n",
    "                    try:\n",
    "                        if not bool(self.is_consolidating(stage2)):\n",
    "                            continue\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "                    # Stage 3: Doji + low volume\n",
    "                    stage3_idx = stage2_start + h2\n",
    "                    row = df.iloc[stage3_idx]\n",
    "                    if self.is_doji(row) and self.is_volume_dropped(stage3_idx, df):\n",
    "                        # Buy next bar, sell one bar later\n",
    "                        if stage3_idx + 2 < n:\n",
    "                            buy_row = df.iloc[stage3_idx + 1]\n",
    "                            sell_row = df.iloc[stage3_idx + 2]\n",
    "                            trade = {\n",
    "                                \"stage1_range\": rise,\n",
    "                                \"buy_time\": buy_row.name,\n",
    "                                \"sell_time\": sell_row.name,\n",
    "                                \"buy_price\": float(buy_row['Open']),\n",
    "                                \"sell_price\": float(sell_row['Open']),\n",
    "                                \"profit\": float(sell_row['Open'] - buy_row['Open'])\n",
    "                            }\n",
    "                            signals.append(trade)\n",
    "                    break  # break inner loop after valid stage2 attempt\n",
    "                break  # break if stage1 found\n",
    "        return signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d6a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backtest_hourly.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def run_backtest(signals: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run a backtest on a list of trade signals.\n",
    "    Each signal should have buy_time, sell_time, buy_price, sell_price, and profit.\n",
    "    \"\"\"\n",
    "    if not signals:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"buy_time\", \"sell_time\", \"buy_price\", \"sell_price\", \"profit\"\n",
    "        ])\n",
    "\n",
    "    df = pd.DataFrame(signals)\n",
    "    df[\"return_pct\"] = (df[\"sell_price\"] - df[\"buy_price\"]) / df[\"buy_price\"] * 100\n",
    "    df[\"cumulative_profit\"] = df[\"profit\"].cumsum()\n",
    "    df[\"cumulative_return\"] = df[\"return_pct\"].cumsum()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5ee609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.py\n",
    "# We use the yfinance library to fetch hourly stock data from Yahoo Finance. \n",
    "# The fetch_data function retrieves the hourly OHLCV (Open, High, Low, Close, Volume) data for a given stock symbol and date range. \n",
    "# We also include a get_stock_metadata function to fetch basic company info (like sector and industry), \n",
    "# which could be used in extended logic (though our pattern doesn‚Äôt utilize it yet).\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(symbol: str, start_date: str, end_date: str, interval: str = \"1h\") -> pd.DataFrame:\n",
    "    df = yf.download(symbol, start=start_date, end=end_date, interval=interval, auto_adjust=False, progress=False)\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data returned for {symbol}. Check ticker or network.\")\n",
    "    if df.index.tz is None:\n",
    "        df.index = df.index.tz_localize(\"UTC\").tz_convert(\"America/New_York\")\n",
    "    else:\n",
    "        df.index = df.index.tz_convert(\"America/New_York\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_stock_metadata(symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves basic metadata for the given stock (e.g., sector, industry).\n",
    "    :param symbol: Stock ticker symbol.\n",
    "    :return: Dictionary with metadata like {'sector': ..., 'industry': ...}.\n",
    "    \"\"\"\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    info = ticker.info\n",
    "    return {\n",
    "        \"sector\": info.get(\"sector\"),\n",
    "        \"industry\": info.get(\"industry\"),\n",
    "        \"long_name\": info.get(\"longName\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb7efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning - Certain functionality \n",
      "             requires requests_html, which is not installed.\n",
      "             \n",
      "             Install using: \n",
      "             pip install requests_html\n",
      "             \n",
      "             After installation, you may have to restart your Python session.\n",
      "30\n",
      "\n",
      "=== Running for AAPL ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing AAPL: No data returned for AAPL. Check ticker or network.\n",
      "\n",
      "=== Running for AMGN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AMGN']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing AMGN: No data returned for AMGN. Check ticker or network.\n",
      "\n",
      "=== Running for AMZN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AMZN']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing AMZN: No data returned for AMZN. Check ticker or network.\n",
      "\n",
      "=== Running for AXP ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AXP']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing AXP: No data returned for AXP. Check ticker or network.\n",
      "\n",
      "=== Running for BA ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['BA']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing BA: No data returned for BA. Check ticker or network.\n",
      "\n",
      "=== Running for CAT ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['CAT']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing CAT: No data returned for CAT. Check ticker or network.\n",
      "\n",
      "=== Running for CRM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['CRM']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing CRM: No data returned for CRM. Check ticker or network.\n",
      "\n",
      "=== Running for CSCO ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['CSCO']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing CSCO: No data returned for CSCO. Check ticker or network.\n",
      "\n",
      "=== Running for CVX ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['CVX']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing CVX: No data returned for CVX. Check ticker or network.\n",
      "\n",
      "=== Running for DIS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['DIS']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing DIS: No data returned for DIS. Check ticker or network.\n",
      "\n",
      "=== Running for GS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['GS']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing GS: No data returned for GS. Check ticker or network.\n",
      "\n",
      "=== Running for HD ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['HD']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing HD: No data returned for HD. Check ticker or network.\n",
      "\n",
      "=== Running for HON ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['HON']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing HON: No data returned for HON. Check ticker or network.\n",
      "\n",
      "=== Running for IBM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['IBM']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing IBM: No data returned for IBM. Check ticker or network.\n",
      "\n",
      "=== Running for JNJ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['JNJ']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing JNJ: No data returned for JNJ. Check ticker or network.\n",
      "\n",
      "=== Running for JPM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['JPM']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing JPM: No data returned for JPM. Check ticker or network.\n",
      "\n",
      "=== Running for KO ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['KO']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing KO: No data returned for KO. Check ticker or network.\n",
      "\n",
      "=== Running for MCD ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['MCD']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing MCD: No data returned for MCD. Check ticker or network.\n",
      "\n",
      "=== Running for MMM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['MMM']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing MMM: No data returned for MMM. Check ticker or network.\n",
      "\n",
      "=== Running for MRK ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['MRK']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing MRK: No data returned for MRK. Check ticker or network.\n",
      "\n",
      "=== Running for MSFT ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['MSFT']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing MSFT: No data returned for MSFT. Check ticker or network.\n",
      "\n",
      "=== Running for NKE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['NKE']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NKE: No data returned for NKE. Check ticker or network.\n",
      "\n",
      "=== Running for NVDA ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['NVDA']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NVDA: No data returned for NVDA. Check ticker or network.\n",
      "\n",
      "=== Running for PG ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['PG']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing PG: No data returned for PG. Check ticker or network.\n",
      "\n",
      "=== Running for SHW ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['SHW']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SHW: No data returned for SHW. Check ticker or network.\n",
      "\n",
      "=== Running for TRV ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['TRV']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing TRV: No data returned for TRV. Check ticker or network.\n",
      "\n",
      "=== Running for UNH ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['UNH']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing UNH: No data returned for UNH. Check ticker or network.\n",
      "\n",
      "=== Running for V ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['V']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing V: No data returned for V. Check ticker or network.\n",
      "\n",
      "=== Running for VZ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['VZ']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing VZ: No data returned for VZ. Check ticker or network.\n",
      "\n",
      "=== Running for WMT ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['WMT']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing WMT: No data returned for WMT. Check ticker or network.\n"
     ]
    }
   ],
   "source": [
    "# run_hourly_pattern.py\n",
    "\n",
    "from pattern import PatternDetector, PatternParams\n",
    "from backtest import run_backtest\n",
    "from data import fetch_data\n",
    "import sys\n",
    "from yahoo_fin import stock_info as si\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# df1 = pd.DataFrame(si.tickers_sp500())\n",
    "# df1 = pd.DataFrame( si.tickers_nasdaq() )\n",
    "df1 = pd.DataFrame( si.tickers_dow() )\n",
    "symbols = df1[0].tolist()[:50]\n",
    "print(len(df1))\n",
    "\n",
    "start_date = \"2024-03-01\"\n",
    "end_date = \"2025-03-01\"\n",
    "\n",
    "\n",
    "for symbol in symbols:\n",
    "    print(f\"\\n=== Running for {symbol} ===\")\n",
    "    try:\n",
    "        df = fetch_data(symbol, start_date, end_date, interval=\"1h\")\n",
    "        detector = PatternDetector(PatternParams())\n",
    "        signals = detector.find_signals(df)\n",
    "        results = run_backtest(signals)\n",
    "\n",
    "        print(\"\\n--- Trade Summary ---\")\n",
    "        print(results)\n",
    "        print(\"\\nTotal Trades:\", len(results))\n",
    "        print(\"Total Profit:\", results['profit'].sum() if 'profit' in results else 0)\n",
    "        if 'return_pct' in results.columns:\n",
    "            print(\"Total Return %:\", results['return_pct'].sum())\n",
    "        else:\n",
    "            print(\"Total Return %: 0\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {symbol}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ca52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# üîê Replace this with your actual Alpha Vantage API key\n",
    "ALPHA_VANTAGE_API_KEY = \"W5EXBDLHMG8TRB7M\"\n",
    "BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "def fetch_data(symbol, interval=\"60min\"):\n",
    "    \"\"\"\n",
    "    Fetches intraday stock data (60-minute intervals) from Alpha Vantage.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): Stock ticker (e.g., \"AAPL\")\n",
    "        interval (str): Time interval (\"60min\" recommended)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with datetime index and OHLCV columns\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"function\": \"TIME_SERIES_INTRADAY\",\n",
    "        \"symbol\": symbol,\n",
    "        \"interval\": interval,\n",
    "        \"apikey\": ALPHA_VANTAGE_API_KEY,\n",
    "        \"outputsize\": \"full\",\n",
    "        \"datatype\": \"json\"\n",
    "    }\n",
    "\n",
    "    print(f\"Requesting Alpha Vantage data for {symbol}...\")\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Request failed: {response.status_code} ‚Äî {response.text}\")\n",
    "\n",
    "    data = response.json()\n",
    "    key = f\"Time Series ({interval})\"\n",
    "    if key not in data:\n",
    "        raise ValueError(f\"Unexpected response format: {data}\")\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data[key], orient=\"index\")\n",
    "    df.columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    df = df.astype(float)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.index = df.index.tz_localize(\"America/New_York\")\n",
    "\n",
    "    return df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "125b80bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting Alpha Vantage data for AAPL...\n",
      "                             Open      High       Low     Close      Volume\n",
      "2025-04-09 04:00:00-04:00  172.10  177.1900  172.1000  175.5400    509199.0\n",
      "2025-04-09 05:00:00-04:00  175.54  176.4500  174.4000  175.1900    212987.0\n",
      "2025-04-09 06:00:00-04:00  175.17  177.1400  173.8500  176.1600    303209.0\n",
      "2025-04-09 07:00:00-04:00  176.09  176.4600  168.3800  168.7400   1369332.0\n",
      "2025-04-09 08:00:00-04:00  174.96  188.4220  168.0000  172.0100   2455832.0\n",
      "...                           ...       ...       ...       ...         ...\n",
      "2025-05-08 15:00:00-04:00  198.62  199.6880  197.1640  197.4000   7354331.0\n",
      "2025-05-08 16:00:00-04:00  197.49  202.0051  197.2000  197.3000  18970508.0\n",
      "2025-05-08 17:00:00-04:00  197.30  202.0051  197.1500  197.5000   1246081.0\n",
      "2025-05-08 18:00:00-04:00  197.50  197.5000  197.3301  197.4994     74501.0\n",
      "2025-05-08 19:00:00-04:00  197.49  197.6000  197.3500  197.4400     40057.0\n",
      "\n",
      "[336 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(fetch_data(\"AAPL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc89257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\22348\\Capital2025\\Stocks\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(\"Python executable:\", sys.executable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
